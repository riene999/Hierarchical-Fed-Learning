{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg 30, 86.71\\tiny{$\\pm$1.87}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 88.86\\tiny{$\\pm$1.60}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n",
      "Avg 30, 89.73\\tiny{$\\pm$1.23}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 91.33\\tiny{$\\pm$1.49}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n",
      "Avg 30, 92.27\\tiny{$\\pm$0.57}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 92.83\\tiny{$\\pm$0.69}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n",
      "----\n",
      "Avg 30, 85.77\\tiny{$\\pm$1.96}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 87.60\\tiny{$\\pm$1.56}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n",
      "Avg 30, 88.55\\tiny{$\\pm$1.19}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 89.66\\tiny{$\\pm$1.41}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n",
      "Avg 30, 90.70\\tiny{$\\pm$0.50}  FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\n",
      "Avg 30, 90.92\\tiny{$\\pm$0.64}  CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "You can 1) perform smoothing on the original standard deviation \n",
    "or 2) calculate the standard deviation on the smoothing data.\n",
    "If using 1), please use the smoothing in preprocess_data, \n",
    "If using 2), please use the smoothing in plot_mean;\n",
    "To the best of our known, both are correct. Here we use the first method.\n",
    "'''\n",
    "\n",
    "import sys \n",
    "sys.path.append(\"/home/moon/data/exps/SFL/\")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sim.utils.record_utils import read_fromcsv\n",
    "from plots.plot_utils import moving_average, save_fig_timestamp\n",
    "\n",
    "def preprocess_data(base_files, setup, path):\n",
    "    seeds = [0,1,2]\n",
    "    yi = setup['yi']\n",
    "\n",
    "    data_settings = []\n",
    "    # construct data with different seeds\n",
    "    for i in range(len(base_files)):\n",
    "        data_per_setting = [] # with multiple seeds\n",
    "        data_last_xround_per_setting = [] # with multiple seeds\n",
    "        for j in range(len(seeds)):\n",
    "            tfile = re.sub(r'seed\\d+', 'seed{}'.format(seeds[j]), base_files[i])\n",
    "            tfile = f'{tfile}.csv' if '.csv' not in tfile else tfile\n",
    "            #print(tfile)\n",
    "            if not os.path.exists(os.path.join(path, tfile)):\n",
    "                if setup['out']:\n",
    "                    print('\\tNot found {}'.format(tfile))\n",
    "                    pass\n",
    "                continue\n",
    "            df = read_fromcsv(tfile, path)\n",
    "            if df['round'].values[-1] != setup['end']:\n",
    "                if setup['out']:\n",
    "                    print('\\tNot completed {}'.format(tfile))\n",
    "                    pass\n",
    "                continue\n",
    "            # pick the data we want to plot\n",
    "            # step = df['round'].values[1] - df['round'].values[0]\n",
    "            # df = df[df['round'].isin([i for i in range(0, setup['end']+1, step)])]\n",
    "            df = df[df['round'] <= setup['end']]\n",
    "            # results over last x round \n",
    "            out = df.iloc[:, yi].values[-setup['select']:]\n",
    "            data_last_xround_per_setting.extend(out.tolist())\n",
    "            x = df['round'].values\n",
    "            y = df.iloc[:, yi].values\n",
    "            \n",
    "            # if setup['smooth']:\n",
    "            #     window_size = int(0.05*setup['end']*0.25) # 0.01*setup['end']*0.25\n",
    "            #     y_smooth = moving_average(y_content, window_size)\n",
    "            #     # adjust the length of the smooth data\n",
    "            #     # discard `len(data)- (len(data)-len(windows)+1)=len(windows)-1` data points\n",
    "            #     x_smooth = x[len(x)-len(y_smooth):]\n",
    "            #     # back to the original variable\n",
    "            #     x, y_content = x_smooth, y_smooth\n",
    "\n",
    "            # data per seed\n",
    "            if len(data_per_setting) == 0:\n",
    "                data_per_setting = y\n",
    "            else:\n",
    "                data_per_setting =  np.vstack((data_per_setting, y))\n",
    "        if setup['out']:\n",
    "            pass\n",
    "            print('Avg {}, {:5.2f}\\\\tiny{{$\\\\pm${:5<.2f}}}  {}'.format(len(data_last_xround_per_setting), np.mean(data_last_xround_per_setting), np.std(data_last_xround_per_setting), base_files[i]))\n",
    "            #print('&{:5.2f}\\\\tiny{{$\\\\pm${:5<.2f}}}'.format(np.mean(data_last_xround_per_setting), np.std(data_last_xround_per_setting)), end=' ')\n",
    "        data_settings.append(data_per_setting)\n",
    "    return x, data_settings\n",
    "\n",
    "    \n",
    "def get_title(filename):\n",
    "    args = filename.split('_')\n",
    "    model_dict = {\n",
    "        'logistic':  'Logisitc',\n",
    "        'mlp': 'MLP',\n",
    "        'lenet5': 'LeNet-5',\n",
    "        'cnnmnist': 'CNN',\n",
    "        'wvgg9k4': 'VGG-9',\n",
    "        'resnetii18': 'ResNet-18'\n",
    "        }\n",
    "    #model = model_dict[args[5]]\n",
    "    dataset_dict = {\n",
    "        'mnist': 'MNIST', \n",
    "        'fashionmnist': 'FMNIST',\n",
    "        'cifar10': 'CIFAR-10',\n",
    "        'cifar100': 'CIFAR-100',\n",
    "        'cinic10': 'CINIC-10'\n",
    "    }\n",
    "    dataset = dataset_dict[args[5]]\n",
    "    #return '{}, {}, {}'.format(dataset, partition, K)\n",
    "    return dataset\n",
    "\n",
    "def format_y_ticks1(y, pos):\n",
    "    return f'{y:.2f}'\n",
    "\n",
    "def format_y_ticks2(y, pos):\n",
    "    return f'{y:.0f}'\n",
    "\n",
    "def plot_avg(ax, base_files, setup, path):    \n",
    "    args = base_files[0].split('_')\n",
    "    ylabels = ['Round', 'Training Loss', 'Training Top1 Accuracy (%)', 'Training Top5 Accuracy (%)', 'Test Loss', 'Test Top1 Accuracy (%)', 'Test Top5 Accuracy (%)']\n",
    "    xlabel = 'Training rounds' \n",
    "\n",
    "    x, data_settings = preprocess_data(base_files, setup=setup, path=path)\n",
    "    #print(len(np.array(data_settings).shape))\n",
    "    for i, base_file in enumerate(base_files):\n",
    "        if len(np.array(data_settings).shape) == 2:\n",
    "            mean = data_settings[i]\n",
    "            std = np.zeros_like(mean)\n",
    "        else:\n",
    "            mean = data_settings[i].mean(axis=0)\n",
    "            std = data_settings[i].std(axis=0)\n",
    "        # smooth\n",
    "        if setup['smooth']:\n",
    "            window_size = int(5) # 0.01*setup['end']*0.25\n",
    "            mean_smooth = moving_average(mean, window_size)\n",
    "            std_smooth = moving_average(std, window_size)\n",
    "            x_smooth = x[len(x)-len(mean_smooth):]\n",
    "            # back to the original variable\n",
    "            x, mean, std = x_smooth, mean_smooth, std_smooth\n",
    "\n",
    "        ax.plot(x, mean, linestyle=None, color='C{}'.format(i), lw=2, label=setup['label'][i])\n",
    "        ax.fill_between(x, mean-std, mean+std, facecolor='C{}'.format(i), alpha=0.2)\n",
    "        # plt.fill_between(x_axis, FedAvgdata[i].min(axis=0), FedAvgdata[i].max(axis=0), facecolor=colors[i], alpha=0.25) \n",
    "         \n",
    "    #ax.set_title(get_title(base_file), fontsize=20)\n",
    "    if setup['yi'] == 1 or setup['yi'] == 4:\n",
    "        ax.set_yscale('log')\n",
    "        #ax.set_ylim(ymax=1)\n",
    "        pass\n",
    "    if setup['yi'] == 1:\n",
    "        ax.legend(loc='upper right', ncol=1, prop={'size': 18}) # loc = 1 or 4\n",
    "    ax.set_ylabel(ylabels[setup['yi']], fontsize=16)\n",
    "    ax.set_xlabel(xlabel, fontsize=16)\n",
    "    ax.tick_params(labelsize=12)\n",
    "    ax.set_xlim(xmin=0, xmax=setup['end'])\n",
    "    \n",
    "    #formatter = ticker.FuncFormatter(format_y_ticks2)\n",
    "    #axs.yaxis.set_major_formatter(formatter)\n",
    "    #axs.grid()\n",
    "    #if 'exdir1' in patterns[0] and 'cifar10' in patterns[0] and 'wvgg9k4' in patterns[0]:\n",
    "    #ax.legend(loc=4, ncol=1, prop={'size': 15}) # loc = 1 or 4\n",
    "    #filename = 'mean_{}_{}_{}'.format(args[5], args[6], args[7])\n",
    "    #print(filename)\n",
    "    #plt.savefig('../figs/{}.png'.format(filename), bbox_inches='tight', dpi=300)\n",
    "\n",
    "\n",
    "def main():\n",
    "    dataset = 'fashionmnist'\n",
    "    path = f'/home/moon/data/exps/SFL/save/{dataset}/'\n",
    "    base_files = [\n",
    "\"FedAvg1.0_M1000,10_K5_R5000,10_wvgg9k4_cinic10_exdir5,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "\"CWT_M1000,10_K5_R5000,10_wvgg9k4_cinic10_exdir5,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "    ]\n",
    "    \n",
    "    # fig, axs = plt.subplots(1, 4, figsize=(22, 4))\n",
    "    # for i in range(4):\n",
    "    #     plot_avg(axs[i], base_files, setup={'out': 1, \"smooth\": 1, 'yi': [1, 2, 4, 5][i], 'select': 10, 'end': 5000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "    # fig.tight_layout()\n",
    "    #save_fig_timestamp(fig, '.png', '../figs/')\n",
    "\n",
    "    # Create a global legend using the handles and labels from the first subplot\n",
    "    #handles, labels = axs[0].get_legend_handles_labels()\n",
    "    #fig.legend(handles, labels, loc='upper right', ncols=2)\n",
    "    #fig.subplots_adjust(wspace=0.25)\n",
    "\n",
    "    \n",
    "#     setup = {'out': 1, \"smooth\": 1, 'yi': 5, 'select': 10, 'end': 5000, 'label': ['PFL', 'SFL']}\n",
    "#     fig, axs = plt.subplots(1, 3, figsize=(13.5, 3.6))\n",
    "#     base_files = [\n",
    "# \"FedAvg1.0_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir1,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "# \"CWT_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir1,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "#     ]\n",
    "#     plot_avg(axs[0], base_files, setup=setup, path=path)\n",
    "    \n",
    "\n",
    "#     base_files = [\n",
    "# \"FedAvg1.0_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir2,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "# \"CWT_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir2,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "\n",
    "#     ]\n",
    "#     plot_avg(axs[1], base_files, setup=setup, path=path)\n",
    "\n",
    "#     base_files = [\n",
    "# \"FedAvg1.0_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir5,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "# \"CWT_M500,10_K5_R5000,10_wvgg9k4_cifar10_exdir5,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "#     ]\n",
    "#     plot_avg(axs[2], base_files, setup=setup, path=path)\n",
    "\n",
    "#     for i in range(3):\n",
    "#         axs[i].set_title('$C={}$'.format([1,2,5][i]), fontsize=18)\n",
    "#         axs[i].set_ylim(ymin=20, ymax=85)\n",
    "#     axs[0].legend(loc=4, ncol=1, prop={'size': 16}) # loc = 1 or 4\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "\n",
    "\n",
    "    #fig.savefig('{}/{}{}'.format(f'/home/moon/data/exps/sequential_local_sgd/figs/', 'test-acc-{}'.format(dataset), '.pdf'), bbox_inches='tight', dpi=300)\n",
    "    base_files = [\n",
    "\"FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "\"CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir1,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "\n",
    "\"FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "\"CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir2,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "\n",
    "\"FedAvg1.0_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.1,0.0,0.0_exp1.0_b20_seed0_clip10\",\n",
    "\"CWT_M500,10_K5_R2000,10_cnn_fashionmnist_exdir5,100.0_sgd0.01,0.0,0.0_exp1.0_b20_seed0_clip50\",\n",
    "    ]\n",
    "    preprocess_data(base_files, setup={'out': 1, \"smooth\": 1, 'yi': 2, 'select': 10, 'end': 2000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "    print('----')\n",
    "    preprocess_data(base_files, setup={'out': 1, \"smooth\": 1, 'yi': 5, 'select': 10, 'end': 2000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "    #preprocess_data(base_files, setup={'out': 1, \"smooth\": 1, 'yi': 5, 'select': 10, 'end': 5000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "    #preprocess_data(base_files, setup={'out': 1, \"smooth\": 1, 'yi': 5, 'select': 10, 'end': 5000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "    #preprocess_data(base_files, setup={'out': 1, \"smooth\": 1, 'yi': 5, 'select': 10, 'end': 5000, 'label': ['PFL', 'SFL']}, path=path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
